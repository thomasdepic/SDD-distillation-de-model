{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TpY05pUGrhr"
      },
      "source": [
        "# Distillation de connaissances dans un réseau de neurone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k85YN_euGrhs",
        "outputId": "2905bf04-fe8b-414c-c6a9-b76237e0fb21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torchinfo\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import Tensor, optim\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import detectors\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABtkbwhWGrht",
        "outputId": "c3f2c143-5ea2-45ad-99b6-5ae5373eb679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using Apple Silicon GPU (MPS)\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"✓ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"✓ Using Apple Silicon GPU (MPS)\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"⚠ Using CPU - training will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkTLeVgRGrhu"
      },
      "source": [
        "# DATA SET : MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF0yrI5MGrhu",
        "outputId": "3ae4a104-cb67-44f9-dfc3-a4ef54046f2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 59.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.75MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.8MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.55MB/s]\n"
          ]
        }
      ],
      "source": [
        "# set batch_size\n",
        "batch_size = 128\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "# we normalize data to have values between -1 and 1\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5]) ])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "train_iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syYOKAhIGrhu",
        "outputId": "616cd0bc-0860-4007-aca5-81af3a22157e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.5], std=[0.5])\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "iNO7pLPYGrhv",
        "outputId": "664520a8-6e73-4e60-f75f-acd4cb9caa9d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_test_samples = 16 # number of digits to plot\n",
        "\n",
        "# create figure for plotting\n",
        "size_figure_grid = int(math.sqrt(num_test_samples))\n",
        "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
        "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
        "    ax[i,j].get_xaxis().set_visible(False)\n",
        "    ax[i,j].get_yaxis().set_visible(False)\n",
        "\n",
        "# load a batch of training data\n",
        "images, labels = next(train_iterator)\n",
        "\n",
        "# show a subpart of it\n",
        "for k in range(num_test_samples):\n",
        "    i = k//4\n",
        "    j = k%4\n",
        "    ax[i,j].cla()\n",
        "    ax[i,j].imshow(images[k,:].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
        "    display.clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baTQirZtGrhv"
      },
      "source": [
        "# Réseau de classification classique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR-jBY-hGrhv"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic convolutional block: Conv → ReLU → Conv → ReLU\n",
        "    Used for classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vJ_isS_Grhv"
      },
      "source": [
        "## The teacher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMAUK25mGrhv"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWSWuzWyGrhw"
      },
      "outputs": [],
      "source": [
        "class Discriminator256channels(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = ConvBlock(1, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 64*14×14\n",
        "\n",
        "        # level 2: 64*14*14\n",
        "        self.conv2 = ConvBlock(64,128)\n",
        "        self.pool2 = nn.MaxPool2d(2) # → 128*7×7\n",
        "\n",
        "        # level 3: 128*7*7\n",
        "        self.conv3 = ConvBlock(128,256)\n",
        "        self.pool3 = nn.MaxPool2d(2) # → 256*3×3\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(in_features= 256 * 3 * 3, out_features=256)\n",
        "        self.linear2 = nn.Linear(in_features=256,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        features = self.pool1(x1)\n",
        "\n",
        "        x2 = self.conv2(features)\n",
        "        features = self.pool2(x2)\n",
        "\n",
        "        x3 = self.conv3(features)\n",
        "        features = self.pool3(x3)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsxNJluoGrhw"
      },
      "outputs": [],
      "source": [
        "# Instantiate model\n",
        "teacher_model = Discriminator256channels().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgFGmLFsGrhw",
        "outputId": "7ea51c93-f23c-489f-9bcb-fb04740bc25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Discriminator Architecture:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Discriminator256channels                 [1, 10]                   --\n",
              "├─ConvBlock: 1-1                         [1, 64, 28, 28]           --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 28, 28]           640\n",
              "│    └─ReLU: 2-2                         [1, 64, 28, 28]           --\n",
              "│    └─Conv2d: 2-3                       [1, 64, 28, 28]           36,928\n",
              "│    └─ReLU: 2-4                         [1, 64, 28, 28]           --\n",
              "├─MaxPool2d: 1-2                         [1, 64, 14, 14]           --\n",
              "├─ConvBlock: 1-3                         [1, 128, 14, 14]          --\n",
              "│    └─Conv2d: 2-5                       [1, 128, 14, 14]          73,856\n",
              "│    └─ReLU: 2-6                         [1, 128, 14, 14]          --\n",
              "│    └─Conv2d: 2-7                       [1, 128, 14, 14]          147,584\n",
              "│    └─ReLU: 2-8                         [1, 128, 14, 14]          --\n",
              "├─MaxPool2d: 1-4                         [1, 128, 7, 7]            --\n",
              "├─ConvBlock: 1-5                         [1, 256, 7, 7]            --\n",
              "│    └─Conv2d: 2-9                       [1, 256, 7, 7]            295,168\n",
              "│    └─ReLU: 2-10                        [1, 256, 7, 7]            --\n",
              "│    └─Conv2d: 2-11                      [1, 256, 7, 7]            590,080\n",
              "│    └─ReLU: 2-12                        [1, 256, 7, 7]            --\n",
              "├─MaxPool2d: 1-6                         [1, 256, 3, 3]            --\n",
              "├─Flatten: 1-7                           [1, 2304]                 --\n",
              "├─Linear: 1-8                            [1, 256]                  590,080\n",
              "├─ReLU: 1-9                              [1, 256]                  --\n",
              "├─Linear: 1-10                           [1, 10]                   2,570\n",
              "==========================================================================================\n",
              "Total params: 1,736,906\n",
              "Trainable params: 1,736,906\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 116.83\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 1.41\n",
              "Params size (MB): 6.95\n",
              "Estimated Total Size (MB): 8.36\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model summary\n",
        "print(\"\\nDiscriminator Architecture:\")\n",
        "torchinfo.summary(teacher_model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68_WFzEMGrhx"
      },
      "source": [
        "### Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-ooS8peGrhx",
        "outputId": "690d9129-bea9-4d43-dd9e-02d15d323f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function: CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0005\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 5e-4\n",
        "\n",
        "# Loss function: Binary Cross Entropy for binary segmentation\n",
        "# Input: (B, 1, 10) probabilities after sigmoid, Target: (B,) probability expextation between 0,1,2,3,4,5,6,7,8,9\n",
        "# We use BCELoss since Sigmoid is already applied in the model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(teacher_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Loss function: {criterion}\")\n",
        "print(f\"Optimizer: {optimizer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcoHG1Y8Grhx"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKAg71vRGrhy",
        "outputId": "4dee44c5-ff39-4d57-a7bf-3945853ce349"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 469/469 [00:43<00:00, 10.66it/s, loss=0.0798, acc=92.64%]\n",
            "Epoch 2/5: 100%|██████████| 469/469 [00:43<00:00, 10.71it/s, loss=0.0403, acc=98.61%]\n",
            "Epoch 3/5: 100%|██████████| 469/469 [00:44<00:00, 10.65it/s, loss=0.0060, acc=99.03%]\n",
            "Epoch 4/5: 100%|██████████| 469/469 [00:48<00:00,  9.58it/s, loss=0.0156, acc=99.22%]\n",
            "Epoch 5/5: 100%|██████████| 469/469 [00:51<00:00,  9.09it/s, loss=0.0289, acc=99.37%]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    teacher_model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch+1}/{EPOCHS}\",\n",
        "        leave=True\n",
        "    )\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward\n",
        "        logits = teacher_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        running_loss += loss.item()\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{loss.item():.4f}\",\n",
        "            \"acc\": f\"{100 * correct / total:.2f}%\"\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9itcqjCGrhy"
      },
      "outputs": [],
      "source": [
        "torch.save(teacher_model.state_dict(), \"teacher_mnist.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjBpk7BzGrhy"
      },
      "source": [
        "## Smaller model : less channels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPcMEhdTGrhy"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu_wXHynGrhy"
      },
      "outputs": [],
      "source": [
        "class Discriminator32channels(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = ConvBlock(1, 8)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 8*14×14\n",
        "\n",
        "        # level 2: 8*14*14\n",
        "        self.conv2 = ConvBlock(8,16)\n",
        "        self.pool2 = nn.MaxPool2d(2) # → 16*7×7\n",
        "\n",
        "        # level 3: 16*7*7\n",
        "        self.conv3 = ConvBlock(16,32)\n",
        "        self.pool3 = nn.MaxPool2d(2) # → 32*3×3\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(in_features= 32 * 3 * 3, out_features=32)\n",
        "        self.linear2 = nn.Linear(in_features=32,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        features = self.pool1(x1)\n",
        "\n",
        "        x2 = self.conv2(features)\n",
        "        features = self.pool2(x2)\n",
        "\n",
        "        x3 = self.conv3(features)\n",
        "        features = self.pool3(x3)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCDt-ZUbGrhz"
      },
      "outputs": [],
      "source": [
        "class Discriminator16channels(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = ConvBlock(1, 4)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 4*14×14\n",
        "\n",
        "        # level 2: 4*14*14\n",
        "        self.conv2 = ConvBlock(4,8)\n",
        "        self.pool2 = nn.MaxPool2d(2) # → 8*7×7\n",
        "\n",
        "        # level 3: 8*7*7\n",
        "        self.conv3 = ConvBlock(8,16)\n",
        "        self.pool3 = nn.MaxPool2d(2) # → 16*3×3\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(in_features= 16 * 3 * 3, out_features=16)\n",
        "        self.linear2 = nn.Linear(in_features=16,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        features = self.pool1(x1)\n",
        "\n",
        "        x2 = self.conv2(features)\n",
        "        features = self.pool2(x2)\n",
        "\n",
        "        x3 = self.conv3(features)\n",
        "        features = self.pool3(x3)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ZoCm0VGrhz"
      },
      "outputs": [],
      "source": [
        "class Discriminator16channelsLessConv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 4*14×14\n",
        "\n",
        "        # level 2: 4*14*14\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2) # → 8*7×7\n",
        "\n",
        "        # level 3: 8*7*7\n",
        "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2) # → 16*3×3\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(in_features= 16 * 3 * 3, out_features=32)\n",
        "        self.linear2 = nn.Linear(in_features=32,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        x1 = self.relu(x1)\n",
        "        features = self.pool1(x1)\n",
        "\n",
        "        x2 = self.conv2(features)\n",
        "        x2 = self.relu(x2)\n",
        "        features = self.pool2(x2)\n",
        "\n",
        "        x3 = self.conv3(features)\n",
        "        x3 = self.relu(x3)\n",
        "        features = self.pool3(x3)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrpGOtiKGrhz"
      },
      "outputs": [],
      "source": [
        "class Discriminator8channelsLessConv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 4*14×14\n",
        "\n",
        "        # level 2: 4*14*14\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2) # → 8*7×7\n",
        "\n",
        "        # level 3: 8*7*7\n",
        "        self.pool3 = nn.MaxPool2d(2) # → 8*3×3\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(in_features= 8 * 3 * 3, out_features=32)\n",
        "        self.linear2 = nn.Linear(in_features=32,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        x1 = self.relu(x1)\n",
        "        features = self.pool1(x1)\n",
        "\n",
        "        x2 = self.conv2(features)\n",
        "        x2 = self.relu(x2)\n",
        "        features = self.pool2(x2)\n",
        "\n",
        "        x3 = self.relu(features)\n",
        "        features = self.pool3(x3)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t32fu68FGrhz"
      },
      "outputs": [],
      "source": [
        "class Discriminator2Conv4channels(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = nn.Conv2d(1, 2, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 2*14×14\n",
        "\n",
        "        # level 2: 2*14*14\n",
        "        self.conv2 = nn.Conv2d(2,4, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2) # → 4*7×7\n",
        "\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(in_features=4*7*7,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        x1 = self.relu(x1)\n",
        "        features = self.pool1(x1)\n",
        "\n",
        "        x2 = self.conv2(features)\n",
        "        x2 = self.relu(x2)\n",
        "        features = self.pool2(x2)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scCmPgBNGrhz"
      },
      "outputs": [],
      "source": [
        "class Discriminator1Conv4channels(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # level 1: 1*28*28\n",
        "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # → 4*14×14\n",
        "\n",
        "\n",
        "        #final classifier\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(in_features=4*3*3,out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = x.view(x.size(0), 1, 28, 28)\n",
        "\n",
        "        x1 = self.conv1(features)\n",
        "        x1 = self.relu(x1)\n",
        "        features = self.pool1(x1)\n",
        "        features = self.pool1(features)\n",
        "        features = self.pool1(features)\n",
        "\n",
        "        out = self.flatten(features)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxALJJkcGrhz"
      },
      "outputs": [],
      "source": [
        "# Instantiate model\n",
        "small_model = Discriminator2Conv4channels().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJmDOlu7Grh0",
        "outputId": "2c4ef7b0-e8ef-485c-a76a-ca87f93ea9de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Discriminator Architecture:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Discriminator2Conv4channels              [1, 10]                   --\n",
              "├─Conv2d: 1-1                            [1, 2, 28, 28]            20\n",
              "├─ReLU: 1-2                              [1, 2, 28, 28]            --\n",
              "├─MaxPool2d: 1-3                         [1, 2, 14, 14]            --\n",
              "├─Conv2d: 1-4                            [1, 4, 14, 14]            76\n",
              "├─ReLU: 1-5                              [1, 4, 14, 14]            --\n",
              "├─MaxPool2d: 1-6                         [1, 4, 7, 7]              --\n",
              "├─Flatten: 1-7                           [1, 196]                  --\n",
              "├─Linear: 1-8                            [1, 10]                   1,970\n",
              "==========================================================================================\n",
              "Total params: 2,066\n",
              "Trainable params: 2,066\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.03\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.02\n",
              "Params size (MB): 0.01\n",
              "Estimated Total Size (MB): 0.03\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model summary\n",
        "print(\"\\nDiscriminator Architecture:\")\n",
        "torchinfo.summary(small_model, input_size=(1, 1, 28, 28), device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwPxhmydGrh0"
      },
      "source": [
        "### Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yQGKUObGrh0",
        "outputId": "8be010fd-e830-4cea-bb87-007d63453816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function: CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0005\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 5e-4\n",
        "\n",
        "# Loss function: Binary Cross Entropy for binary segmentation\n",
        "# Input: (B, 1, 10) probabilities after sigmoid, Target: (B,) probability expextation between 0,1,2,3,4,5,6,7,8,9\n",
        "# We use BCELoss since Sigmoid is already applied in the model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(small_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Loss function: {criterion}\")\n",
        "print(f\"Optimizer: {optimizer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k27Pi61eGrh0"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3wMcf4XGrh0",
        "outputId": "8ddda80d-54ab-458a-ecd5-448be5626af2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 0/391 [00:03<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchvision/models/convnext.py\", line 9, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
            "    from torch._dynamo.utils import is_compile_supported\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 13, in <module>\n",
            "    from . import (\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_dynamo/aot_compile.py\", line 15, in <module>\n",
            "    from . import convert_frame\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 57, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 53, in <module>\n",
            "    from torch._dynamo.exc import ObservedException, TensorifyScalarRestartAnalysis\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_dynamo/exc.py\", line 45, in <module>\n",
            "    from .utils import counters\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 67, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 3, in <module>\n",
            "    import sympy\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sympy/__init__.py\", line 77, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/__init__.py\", line 79, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/rings.py\", line 31, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sympy/printing/__init__.py\", line 5, in <module>\n",
            "    from .latex import latex, print_latex, multiline_latex\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1128, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 759, in _compile_bytecode\n",
            "  File \"<frozen importlib._bootstrap>\", line 491, in _verbose_message\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[222]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m     10\u001b[39m pbar = tqdm(\n\u001b[32m     11\u001b[39m     train_loader,\n\u001b[32m     12\u001b[39m     desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     leave=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1170\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1163\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1164\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    small_model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch+1}/{EPOCHS}\",\n",
        "        leave=True\n",
        "    )\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward\n",
        "        logits = small_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        running_loss += loss.item()\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{loss.item():.4f}\",\n",
        "            \"acc\": f\"{100 * correct / total:.2f}%\"\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaCG4jdGrh0"
      },
      "source": [
        "# Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doTFgwwTGrh0",
        "outputId": "becc4bad-de89-421a-b771-1db8e1eb0c70"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Discriminator256channels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m teacher = \u001b[43mDiscriminator256channels\u001b[49m().to(device)\n\u001b[32m      2\u001b[39m teacher.load_state_dict(torch.load(\u001b[33m\"\u001b[39m\u001b[33mteacher_mnist.pth\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      3\u001b[39m teacher.eval()\n",
            "\u001b[31mNameError\u001b[39m: name 'Discriminator256channels' is not defined"
          ]
        }
      ],
      "source": [
        "teacher = Discriminator256channels().to(device)\n",
        "teacher.load_state_dict(torch.load(\"teacher_mnist.pth\"))\n",
        "teacher.eval()\n",
        "\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "student = Discriminator1Conv4channels().to(device)\n",
        "\n",
        "optimizer = optim.Adam(student.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKsDLrHfGrh0"
      },
      "outputs": [],
      "source": [
        "T = 6.0\n",
        "alpha = 0.8\n",
        "\n",
        "def distillation_loss(student_logits, teacher_logits, labels):\n",
        "    loss_ce = F.cross_entropy(student_logits, labels)\n",
        "\n",
        "    loss_kd = F.kl_div(\n",
        "        F.log_softmax(student_logits / T, dim=1),\n",
        "        F.softmax(teacher_logits / T, dim=1),\n",
        "        reduction=\"batchmean\"\n",
        "    )\n",
        "\n",
        "    return alpha * loss_ce + (1 - alpha) * (T * T) * loss_kd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3JsYP0kGrh0",
        "outputId": "d316d9be-3637-45e3-8b09-e400a974e57d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 469/469 [00:15<00:00, 29.68it/s, loss=6.1555, acc=34.48%]\n",
            "Epoch 2/10:  26%|██▌       | 120/469 [00:04<00:11, 29.23it/s, loss=5.0193, acc=66.30%]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[200]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m optimizer.step()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# stats\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m preds = student_logits.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     41\u001b[39m correct += (preds == labels).sum().item()\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch+1}/{EPOCHS}\",\n",
        "        leave=True\n",
        "    )\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # teacher forward (no grad)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher(images)\n",
        "\n",
        "        # student forward\n",
        "        student_logits = student(images)\n",
        "\n",
        "        # distillation loss\n",
        "        loss = distillation_loss(\n",
        "            student_logits,\n",
        "            teacher_logits,\n",
        "            labels\n",
        "        )\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        running_loss += loss.item()\n",
        "        preds = student_logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # progress bar\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{loss.item():.4f}\",\n",
        "            \"acc\": f\"{100 * correct / total:.2f}%\"\n",
        "        })"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IkTLeVgRGrhu",
        "baTQirZtGrhv",
        "NMAUK25mGrhv",
        "djaCG4jdGrh0"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
